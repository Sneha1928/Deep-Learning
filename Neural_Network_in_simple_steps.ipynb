{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network in simple steps.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ENhG1b9o9Xe9n_piZPgDoP5uD1miL2xF",
      "authorship_tag": "ABX9TyPTOvf9V5raN1Ypzuc9Rstx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sneha1928/Deep-Learning/blob/main/Neural_Network_in_simple_steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykY2w1-_uJGJ"
      },
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6pqAci6vxAo"
      },
      "source": [
        "#importing dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/MY ML PROJECTS/diabetes.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvkLBiIEySa6"
      },
      "source": [
        "[Dataset link](https://drive.google.com/file/d/1oaUPsdIPJqNkBcdnhDyhKBTaReeJw4wg/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Zz5ptGNayGMi",
        "outputId": "a580ccee-0ff1-4c31-c13f-1444f9884db4"
      },
      "source": [
        "# viewing the data\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhaQx8WUyrrw"
      },
      "source": [
        "Here, we have to predict if the patient will have diabetes or not from the diagnostics measurements. Its a type of classification problem. 0 means non-diabetic and 1 means diabetic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-orJSGlzUuG"
      },
      "source": [
        "**Checking the target variable distribution.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "YJps0ew5yks9",
        "outputId": "ff959058-601c-4bf4-e204-b0a0fe3324f5"
      },
      "source": [
        "import seaborn as sns\n",
        "data[\"Outcome\"].value_counts().plot(kind = 'bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f922c78cd10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGODERfPzikx"
      },
      "source": [
        "predictors = data.iloc[:,0:8]\n",
        "response = data.iloc[:,8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAwnExZg0DPd"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(predictors,response,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieja2OnL0eOZ"
      },
      "source": [
        "# Neural network training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7LjkZ2m0joJ"
      },
      "source": [
        "There are two ways to build Keras model:\n",
        "\n",
        "\n",
        "1.   Sequential\n",
        "2.   Functional\n",
        "\n",
        "The sequential API will allow us to model layer by layer.\n",
        "If we need to build arbitrary graphs of layers, Keras functional API can do that for us.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwDlxmfv0VaW"
      },
      "source": [
        "# defining the keras model layer by layer\n",
        "\n",
        "kerasmodel = Sequential() # inintializing model - Dense for fully connected layer\n",
        "kerasmodel.add(Dense(12,input_dim=8,activation=\"relu\")) # First hidden layer\n",
        "kerasmodel.add(Dense(8,activation=\"relu\")) # relu to avoid vanishing exploding problem\n",
        "kerasmodel.add(Dense(1,activation=\"sigmoid\")) # sigmoid since it is binary classification type problem\n",
        "# bias and weight are default metod using glorot_uniform technique"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD7uXDVd3O1f"
      },
      "source": [
        "# compiling the model\n",
        "kerasmodel.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ar9zdT3pIS",
        "outputId": "486e48ac-298f-49c3-b751-79b1c6e1565d"
      },
      "source": [
        "# fitting the model\n",
        "kerasmodel.fit(X_train,y_train,epochs=150,batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 2.7560 - accuracy: 0.5102\n",
            "Epoch 2/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 1.1698 - accuracy: 0.6253\n",
            "Epoch 3/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.8394 - accuracy: 0.6552\n",
            "Epoch 4/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.8100 - accuracy: 0.6395\n",
            "Epoch 5/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.6595\n",
            "Epoch 6/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.7133 - accuracy: 0.6383\n",
            "Epoch 7/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6395\n",
            "Epoch 8/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6786\n",
            "Epoch 9/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6651\n",
            "Epoch 10/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6599\n",
            "Epoch 11/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6948\n",
            "Epoch 12/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6977\n",
            "Epoch 13/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.6727\n",
            "Epoch 14/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7232\n",
            "Epoch 15/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6743\n",
            "Epoch 16/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6692\n",
            "Epoch 17/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7163\n",
            "Epoch 18/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7145\n",
            "Epoch 19/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6881\n",
            "Epoch 20/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7027\n",
            "Epoch 21/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7336\n",
            "Epoch 22/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7168\n",
            "Epoch 23/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7300\n",
            "Epoch 24/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7196\n",
            "Epoch 25/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6939\n",
            "Epoch 26/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7276\n",
            "Epoch 27/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.7183\n",
            "Epoch 28/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7230\n",
            "Epoch 29/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7214\n",
            "Epoch 30/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7289\n",
            "Epoch 31/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7498\n",
            "Epoch 32/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6689\n",
            "Epoch 33/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7444\n",
            "Epoch 34/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7062\n",
            "Epoch 35/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7349\n",
            "Epoch 36/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7310\n",
            "Epoch 37/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7148\n",
            "Epoch 38/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7536\n",
            "Epoch 39/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7082\n",
            "Epoch 40/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7491\n",
            "Epoch 41/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7460\n",
            "Epoch 42/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7480\n",
            "Epoch 43/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7296\n",
            "Epoch 44/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.6903\n",
            "Epoch 45/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7374\n",
            "Epoch 46/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7013\n",
            "Epoch 47/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.6983\n",
            "Epoch 48/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7405\n",
            "Epoch 49/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7101\n",
            "Epoch 50/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7039\n",
            "Epoch 51/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7852\n",
            "Epoch 52/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7355\n",
            "Epoch 53/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.6993\n",
            "Epoch 54/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7344\n",
            "Epoch 55/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7270\n",
            "Epoch 56/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7613\n",
            "Epoch 57/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7247\n",
            "Epoch 58/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7410\n",
            "Epoch 59/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7319\n",
            "Epoch 60/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7311\n",
            "Epoch 61/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7314\n",
            "Epoch 62/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7691\n",
            "Epoch 63/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7330\n",
            "Epoch 64/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7294\n",
            "Epoch 65/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7223\n",
            "Epoch 66/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7353\n",
            "Epoch 67/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7355\n",
            "Epoch 68/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7390\n",
            "Epoch 69/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7639\n",
            "Epoch 70/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7537\n",
            "Epoch 71/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7455\n",
            "Epoch 72/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7386\n",
            "Epoch 73/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7175\n",
            "Epoch 74/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7435\n",
            "Epoch 75/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7345\n",
            "Epoch 76/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7578\n",
            "Epoch 77/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7117\n",
            "Epoch 78/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7327\n",
            "Epoch 79/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7377\n",
            "Epoch 80/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7207\n",
            "Epoch 81/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7586\n",
            "Epoch 82/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7363\n",
            "Epoch 83/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7742\n",
            "Epoch 84/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7630\n",
            "Epoch 85/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7325\n",
            "Epoch 86/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7384\n",
            "Epoch 87/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7227\n",
            "Epoch 88/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7476\n",
            "Epoch 89/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7393\n",
            "Epoch 90/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7425\n",
            "Epoch 91/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7197\n",
            "Epoch 92/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7437\n",
            "Epoch 93/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7535\n",
            "Epoch 94/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7271\n",
            "Epoch 95/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7583\n",
            "Epoch 96/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7391\n",
            "Epoch 97/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7631\n",
            "Epoch 98/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7428\n",
            "Epoch 99/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7412\n",
            "Epoch 100/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7381\n",
            "Epoch 101/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7514\n",
            "Epoch 102/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7695\n",
            "Epoch 103/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7315\n",
            "Epoch 104/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7202\n",
            "Epoch 105/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7563\n",
            "Epoch 106/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7238\n",
            "Epoch 107/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7482\n",
            "Epoch 108/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7300\n",
            "Epoch 109/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7437\n",
            "Epoch 110/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7898\n",
            "Epoch 111/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7588\n",
            "Epoch 112/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7830\n",
            "Epoch 113/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7576\n",
            "Epoch 114/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7289\n",
            "Epoch 115/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7488\n",
            "Epoch 116/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7595\n",
            "Epoch 117/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7340\n",
            "Epoch 118/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7624\n",
            "Epoch 119/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7666\n",
            "Epoch 120/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7456\n",
            "Epoch 121/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7529\n",
            "Epoch 122/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7572\n",
            "Epoch 123/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7860\n",
            "Epoch 124/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7699\n",
            "Epoch 125/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7724\n",
            "Epoch 126/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7669\n",
            "Epoch 127/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7424\n",
            "Epoch 128/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7583\n",
            "Epoch 129/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7221\n",
            "Epoch 130/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7506\n",
            "Epoch 131/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7614\n",
            "Epoch 132/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7675\n",
            "Epoch 133/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7755\n",
            "Epoch 134/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7653\n",
            "Epoch 135/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7764\n",
            "Epoch 136/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7640\n",
            "Epoch 137/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7422\n",
            "Epoch 138/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7688\n",
            "Epoch 139/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7615\n",
            "Epoch 140/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7775\n",
            "Epoch 141/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7675\n",
            "Epoch 142/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7330\n",
            "Epoch 143/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7600\n",
            "Epoch 144/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7825\n",
            "Epoch 145/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7672\n",
            "Epoch 146/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7784\n",
            "Epoch 147/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7528\n",
            "Epoch 148/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7443\n",
            "Epoch 149/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7444\n",
            "Epoch 150/150\n",
            "62/62 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f922a534e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8slFip8H4SQu"
      },
      "source": [
        "# Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgRzM8ia33sJ",
        "outputId": "155e510b-a697-417d-da40-3419084ff13d"
      },
      "source": [
        "_, accuracy = kerasmodel.evaluate(X_train,y_train)\n",
        "print(\"Accuracy of our model is \",accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7655\n",
            "Accuracy of our model is  0.7654722929000854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxkWIUzx4j8v",
        "outputId": "bed16de0-b3ce-4cde-b0fc-9d2121638d2a"
      },
      "source": [
        "# Test accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = kerasmodel.predict_classes(X_test)\n",
        "accu = accuracy_score(y_test,y_pred)\n",
        "print(\"accuracy of test set is \",accu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of test set is  0.7532467532467533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSsCD95j5F5d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}